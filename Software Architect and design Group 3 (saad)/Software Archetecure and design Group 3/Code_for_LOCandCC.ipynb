{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2R6zjNAGmIOG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Define complexity score mapping (A is simplest, F is most complex)\n",
        "complexity_score_map = {\n",
        "    'A': 1,  # Simplest\n",
        "    'B': 2,\n",
        "    'C': 3,\n",
        "    'D': 4,\n",
        "    'E': 5,\n",
        "    'F': 6   # Most complex\n",
        "}\n",
        "\n",
        "# Function to extract LOC from Radon raw output\n",
        "def extract_loc_from_output(raw_output):\n",
        "    loc_pattern = r\"LOC:\\s+(\\d+)\"  # Regex to match LOC value\n",
        "    loc_match = re.search(loc_pattern, raw_output)\n",
        "    if loc_match:\n",
        "        return int(loc_match.group(1))\n",
        "    return 0\n",
        "\n",
        "# Function to extract Cyclomatic Complexity (CC) from Radon CC output\n",
        "def extract_cc_from_output(cc_output):\n",
        "    cc_pattern = r\"- ([A-F])\"  # Regex to match cyclomatic complexity grades\n",
        "    cc_matches = re.findall(cc_pattern, cc_output)\n",
        "\n",
        "    # Convert complexity grades to numerical scores using the mapping\n",
        "    total_cc = sum([complexity_score_map[grade] for grade in cc_matches])\n",
        "    count = len(cc_matches)\n",
        "    average_cc = total_cc / count if count > 0 else 0\n",
        "    return average_cc\n",
        "\n",
        "# Function to clone a GitHub repository into a specific directory\n",
        "def clone_repo(github_link, project_name, base_dir):\n",
        "    project_dir = os.path.join(base_dir, project_name)\n",
        "\n",
        "    # Check if the directory already exists\n",
        "    if not os.path.exists(project_dir):\n",
        "        try:\n",
        "            subprocess.run(['git', 'clone', github_link, project_dir], check=True)\n",
        "            print(f\"Cloned {github_link} into {project_dir}\")\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(f\"Failed to clone {github_link}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"Repository {project_name} already exists in {base_dir}. Skipping clone.\")\n",
        "\n",
        "    return project_dir\n",
        "\n",
        "# Function to run analysis on the cloned repository (no Pylint analysis)\n",
        "def analyze_repo(repo_dir):\n",
        "    total_loc = 0  # To accumulate LOC across all Python files\n",
        "\n",
        "    try:\n",
        "        # Walk through the repository and collect all .py files\n",
        "        for root, dirs, files in os.walk(repo_dir):\n",
        "            for file in files:\n",
        "                if file.endswith('.py'):\n",
        "                    file_path = os.path.join(root, file)\n",
        "\n",
        "                    # Run Radon raw on the individual file to get LOC\n",
        "                    radon_raw_output = subprocess.check_output(['radon', 'raw', file_path]).decode('utf-8')\n",
        "                    total_loc += extract_loc_from_output(radon_raw_output)\n",
        "\n",
        "        # Run Radon CC on the entire repository (directory)\n",
        "        radon_cc_output = subprocess.check_output(['radon', 'cc', repo_dir, '-s']).decode('utf-8')\n",
        "\n",
        "        # Extract Cyclomatic Complexity (average)\n",
        "        extracted_CC = extract_cc_from_output(radon_cc_output)\n",
        "\n",
        "        return total_loc, extracted_CC\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Analysis failed for {repo_dir}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Read the list of projects from the Excel file\n",
        "projects_df = pd.read_excel('project-list.xlsx')  # Use read_excel to read the Excel file\n",
        "\n",
        "# Define the base directory where the repositories will be cloned\n",
        "base_dir = 'cloned_repos'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Prepare a list to store the results for each project\n",
        "results = []\n",
        "\n",
        "# Loop over each project and process it\n",
        "for index, row in projects_df.iterrows():\n",
        "    github_link = row['repo_url']  # Adjust based on your Excel file's column name\n",
        "    project_name = github_link.split('/')[-1].replace('.git', '')  # Use the repo name as project name\n",
        "\n",
        "    # Clone the repository\n",
        "    repo_dir = clone_repo(github_link, project_name, base_dir)\n",
        "\n",
        "    if repo_dir:\n",
        "        # Analyze the repository (LOC and CC only)\n",
        "        loc, cc = analyze_repo(repo_dir)\n",
        "\n",
        "        if loc is not None and cc is not None:\n",
        "            # Store the results for this project\n",
        "            results.append({\n",
        "                'project_name': project_name,\n",
        "                'github_link': github_link,\n",
        "                'lines_of_code': loc,  # Total LOC for the entire project\n",
        "                'cyclomatic_complexity': cc\n",
        "            })\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('LOCandCC.csv', index=False)\n",
        "\n",
        "print(\"Analysis complete for all projects. Results saved to 'multiple_project_analysis_results.csv'.\")\n"
      ]
    }
  ]
}